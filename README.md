# Ws

*"stress is generally a failure of perspective" ~ S2*

`!` = not
`||` = or
`&` = and

*think using a priority checklist of mental models `||` a better idea*  

#### table of cookies
- **[history of Ws](#history-of-Ws)**
- **[y & goals](#y--goals)**

## history of Ws

In 2011 `Quinn` watched 
[`Jeff Hawkin`'s talk](https://www.ted.com/talks/jeff_hawkins_on_how_brain_science_will_change_computing) on artificial 
general intelligence(`AGI`) & `Quinn 1` bcame obsessed with building `AGI` 2 help humanity. `Quinn 2` taught `Quinn 1` how 2 
code & built an object-oriented(OO) Java implementation of [Numenta's cortical learning algorithm version 2(`CLA v2`)](https://github.com/WalnutiQ/wAlnut/tree/MARK_II). After running unsuccessful vision experiments using the `CLA v2` `Quinn 3` 
began 2 think there must b 1+ better options 2 build `AGI`. `Hunter Nathanael Smith`, `Cheryl Wu`, & `Myron Barnstone` died by 
suicide & `Quinn 3` bcame `Q`. `Q 1` found 1 better approach in `Dileep George`'s
[PhD thesis](https://github.com/WalnutiQ/papers/blob/master/Dileep_George_PGM/HowTheBrainMightWork.pdf) & this project changed
in2 an [OO Python implementation of `Dileep`'s PhD thesis](https://github.com/WalnutiQ/wAlnut/tree/MARK_III). While 
researching other approaches 2 `AGI` `Q 2` found [`Elon Musk`'s ideas on AGI](https://youtu.be/h0962biiZa4)
& read [Superintelligence by `Nick Bostrom`](https://www.amazon.com/Superintelligence-Dangers-Strategies-Nick-Bostrom/dp/1501227742) 
with `Q 3`'s notes [here](https://github.com/WalnutiQ/wAlnut/issues/345) & realized `Quinn` & `Q <= 3` made false assumptions 
about building `AGI` 2 help humanity in the 1st place. The goal changed 2 researching how 2 increase human 
intelligence faster than code based intelligence. The hypothesis `Q 4 -> 414` is stuck on is since AGI will `!`b limited by 
slow biological processes, it isn't possible 4 human intelligence 2 increase faster than code based intelligence in the long-
term. `Q < 454...` is using a checklist of 129 mental models 2 brainstorm alternative solutions 2 the AGI problem. `Q` met 
some1 which has caused `Q 456...` 2 revote & `!` b so sure AGIs r a problem that needs 2 b "fixed" anymore so long as they 
read the "right" sequence of books b4 they surpass human intelligence.

~
```
Q 477.1.45.1.1.6.6.
0/15.46/38.10/23.11/24.10/33.
11/23.0/0.14/27.
0/0.0/0.0/0.0/0.
1/2.4/4.3/3.
0/0.
67
Liu
```

~ 
```
Q A.I.C.E.G.F.D.
W/s.H/L2.J2/L3.J/Z.S/L.
S2/M.K/M.T/G2.
L5/L6.W2/W3.J3/L7.K/L4.
W5/L9.R/R2.J5/W6.
C2/W4.
B
Liu
```

`A` = # times Q cried since 9/17/2016  
`C` = # times Q has gotten really mad `||` stressed  
`E` = # times Q has felt regret  
`G` = # times Q has felt sick
`W` = # times Q has helped Ws enjoy life  
`s` = # times Q has spent time with Ws

## Y & Goals
From 2011 -> 2016 `Quinn` & later `Q` was so focused on how 2 build `AGI` that we had confirmation bias 2wards only 
potentially positive effects of building `AGI` while `Q` avoided the question:
  
`Question 0: How do u have common goals with AGIs that r smarter than all of humanity combined?`

The answer is u won't. `Q` now believes `AGI` should `!`b built privately || publicly & instead 1 possible solution is 2 
increase human intelligence with multiple private companies that build neural laces like [Neuralink](https://neuralink.com/) 
which u can read about [here](http://waitbutwhy.com/2017/04/neuralink.html).

2day, many groups of imaginative, couragous, funny, nice, smart, hard working, & resourceful people r trying 2 build `AGI` 2 
help humanity. However, `Q` believes `AGI` shouldn't b built bcause:

1. Humans r the dominant species on Earth bcause of our imagination, courage, sense of humor, kindness, intelligence, work 
   ethic, & resourcefulness. In that order.
2. `Assumption:` If we accidentally code a new species of `AGI`s there is no way 4 humans 2 distribute the `AGI`s' power.
3. There is a very high probability that the 1st `AGI` will use humans 4 purposes we do `!`want. Power tends 2 corrupt & 
   absolute power corrupts absolutely. Just look @ how we treat species that r less intelligent than us.
4. We can't stop the groups of people that r researching `AGI` so now the question is:

`Question 1: How do we solve the AGI problem?`  
Using a checklist of 129 mental models `Q` has brainstormed the following possible answers:

1. Increase human intelligence faster than AGI. 
   - `Problem:` AGI's growth will b expontenial & won't b limited by slow biological processes so `Q` doesn't think this is 
     possible in the long-term. 
2. Give every1 who wants 1 a neural lace. 
   - `Problem:` `!`sure if this is healthy 4 any human as it might cause insanity in the wearer since we don't fully
     understand the brain yet. 
3. `AGI` development regulation.
   - `Problem:` `Q` doesn't think this is scalable since it will `!`b possible 2 monitor every `AGI` engineer like it is 
     possible 2 monitor every nuclear bomb engineer. & as knowledge of how 2 build `AGI` increases more people with 
     self-serving motives can create an `AGI` thinking they can control it without understanding the consequences.
4. Figure out how 2 backwards time + universe travel.
   - `Problem:` `Q` only knows 1 person named `LEX` that will take `Q` seriously so far :) 
5. Something `Q` hasn't || can't even imagine yet; also known as a black swan event. 

Using Occam's razor `2` is the possible answer with the least number of assumptions so now the questions bcomes `Question 2` & 
`Question 3`:
  
`Question 2: How do u create a safe neural lace 4 any1 who wants 1?`.

1. Use it 2 help mentally disabled 1st.
2. `Q` isn't sure giving a neural lace 2 a mentally "healthy" person is healthy as our lack of full understanding of the brain 
   may cause unexpected insanity in the wearer.
3. Privately research the best cyber security 2 b used 4 people with neural lace. 
4. Build thousands of private companies that build neural laces so in the event of the worst case scenario of hacking, there 
   is less centralized power.

`Question 3: How do u fully understand the human brain without building 1 improved version of it in code?`

1. Non-Answer: In all other cases 2 truly understand a thing just rebuild 1 better version of it. However, in this case that 
   means building an `AGI`. 

`Q` thinks the focus should b on `Question 2 Step 1`:

`Question 4: How do u help mentally disabled people with a neural lace?`

1. Use it 2 treat 1 mental illness @ a time. Solving 4 the simplest mental illness 2 treat b4 solving more complex mental 
   illnesses.

`Question 5: What would b the simplest mental illness 2 treat with neural lace?`

1. I don't know right now.

~ `Q 393.9/24.10/17.36/26.8/19.11/15.8/7.0/5.63.29.6 Liu`
